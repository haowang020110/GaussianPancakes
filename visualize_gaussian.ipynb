{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gaussian_viewing_utils import * \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from gaussian_renderer import render, GaussianModel\n",
    "from scene.cameras import Camera as GSCamera\n",
    "from scene.dataset_readers import readRNNSIMSceneInfo\n",
    "import kaolin\n",
    "from scene import Scene\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "\n",
    "def log_tensor(t, name, **kwargs):\n",
    "    print(kaolin.utils.testing.tensor_info(t, name=name, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can come up with a list of model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/sierra/gaussian-splatting/eval_depth_norm2/cecum'\n",
    "#model_path = '/home/sierra/gaussian-splatting/eval/invivo57'\n",
    "\n",
    "# calculate number of views should be length of cameras.json\n",
    "cam_path = os.path.join(model_path, 'cameras.json')\n",
    "with open(cam_path, 'r') as f:\n",
    "    cameras = json.load(f)\n",
    "num_views = len(cameras)\n",
    "\n",
    "# Camera ID\n",
    "novel_view_camera_id = 40   \n",
    "\n",
    "# if visualization folder doesn't exist, make it\n",
    "if not os.path.exists(model_path + '/visualization'):\n",
    "    os.makedirs(model_path + '/visualization')\n",
    "\n",
    "# Novel view visualization output\n",
    "nv_output_path = model_path + f'/visualization/novel-views-around-camera-id{novel_view_camera_id}_xaxis.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineParamsNoparse:\n",
    "    \"\"\" Same as PipelineParams but without argument parser. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.convert_SHs_python = False\n",
    "        self.compute_cov3D_python = False                      \n",
    "        self.debug = False\n",
    "\n",
    "        \n",
    "def load_checkpoint(model_path, sh_degree=3, iteration=-1):\n",
    "    # Find checkpoint\n",
    "    checkpt_dir = os.path.join(model_path, \"point_cloud\")\n",
    "    if iteration == -1:\n",
    "        iteration = searchForMaxIteration(checkpt_dir)\n",
    "    checkpt_path = os.path.join(checkpt_dir, f\"iteration_{iteration}\", \"point_cloud.ply\")\n",
    "    \n",
    "    # Load guassians\n",
    "    gaussians = GaussianModel(sh_degree)\n",
    "    gaussians.load_ply(checkpt_path)                                                 \n",
    "    return gaussians\n",
    "\n",
    "\n",
    "def try_load_camera(model_path, idx=0):\n",
    "    \"\"\" Load one of the default cameras for the scene. \"\"\"\n",
    "    cam_path = os.path.join(model_path, 'cameras.json')\n",
    "    if not os.path.exists(cam_path):\n",
    "        print(f'Could not find saved cameras for the scene at {cam_path}; using default for ficus.')\n",
    "        return GSCamera(colmap_id=0,\n",
    "                        R=np.array([[-9.9037e-01,  2.3305e-02, -1.3640e-01], [ 1.3838e-01,  1.6679e-01, -9.7623e-01], [-1.6444e-09, -9.8571e-01, -1.6841e-01]]), \n",
    "                        T=np.array([6.8159e-09, 2.0721e-10, 4.03112e+00]), \n",
    "                        FoVx=0.69111120, FoVy=0.69111120, \n",
    "                        image=torch.zeros((3, 800, 800)),  # fake \n",
    "                        gt_alpha_mask=None, image_name='fake', uid=0)\n",
    "        \n",
    "    with open(cam_path) as f:\n",
    "        data = json.load(f)\n",
    "        raw_camera = data[idx]\n",
    "        \n",
    "    tmp = np.zeros((4, 4))\n",
    "    tmp[:3, :3] = raw_camera['rotation']\n",
    "    tmp[:3, 3] = raw_camera['position']\n",
    "    tmp[3, 3] = 1\n",
    "    name = raw_camera['img_name']\n",
    "    C2W = np.linalg.inv(tmp)\n",
    "    R = C2W[:3, :3].transpose()\n",
    "    T = C2W[:3, 3]\n",
    "    width = raw_camera['width']\n",
    "    height = raw_camera['height']\n",
    "    fovx = focal2fov(raw_camera['fx'], width)\n",
    "    fovy = focal2fov(raw_camera['fy'], height)\n",
    "    return GSCamera(colmap_id=0,\n",
    "                    R=R, T=T, FoVx=fovx, FoVy=fovy, \n",
    "                    image=torch.zeros((3, height, width)),  # fake \n",
    "                    depth=torch.zeros((height, width)),  # fake\n",
    "                    gt_alpha_mask=None, image_name=name, uid=0)\n",
    "\n",
    "def load_camera_map(camera_file, name_convention='id.png'):\n",
    "    with open(camera_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if name_convention == 'id.png':\n",
    "        return {int(cam['img_name']): cam['id'] for cam in data}\n",
    "    elif name_convention == 'id_color.jpg':\n",
    "        return {int(cam['img_name'].split('_')[0]): cam['id_color'] for cam in data}\n",
    "    else:\n",
    "        raise ValueError('name_convention not recognized')\n",
    "\n",
    "gaussians = load_checkpoint(model_path)\n",
    "pipeline = PipelineParamsNoparse()\n",
    "background = torch.tensor([0, 0, 0], dtype=torch.float32, device=\"cuda\")\n",
    "center_camera = try_load_camera(model_path, idx=novel_view_camera_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args = argparse.Namespace()\n",
    "args.resolution = 1\n",
    "args.model_path = model_path\n",
    "args.source_path = dataset_path\n",
    "args.images = dataset_path + '/images'\n",
    "args.depths = dataset_path + '/depths'\n",
    "args.eval = True\n",
    "args.data_device = 'cuda'\n",
    "\n",
    "scene = Scene(args, gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  7 11:16:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   56C    P2              61W / 300W |   7321MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:61:00.0 Off |                  Off |\n",
      "| 38%   66C    P2             113W / 300W |   5184MiB / 49140MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1664      C   ...nvs/gaussian_splatting38/bin/python     2152MiB |\n",
      "|    0   N/A  N/A      2033      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   2889950      C   python                                     5150MiB |\n",
      "|    1   N/A  N/A      2033      G   /usr/lib/xorg/Xorg                           16MiB |\n",
      "|    1   N/A  N/A      2218      G   /usr/bin/gnome-shell                          5MiB |\n",
      "|    1   N/A  N/A   2890052      C   /opt/conda/bin/python                      5148MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis.mp4.\n",
      "Moviepy - Writing video /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis.mp4\n",
      "Image Video saved to /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis.mp4\n",
      "Moviepy - Building video /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis_depth.mp4.\n",
      "Moviepy - Writing video /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis_depth.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis_depth.mp4\n",
      "Depth Video saved to /home/sierra/gaussian-splatting/eval_depth_norm2/cecum/visualization/novel-views-around-camera-id40_xaxis_depth.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "render_rotate_about_x_path_video(model_path, novel_view_camera_id, 30, 30, nv_output_path, num_steps=200, num_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "depth_images = []\n",
    "# find global min and global max of depths \n",
    "global_min = 100000\n",
    "global_max = -100000\n",
    "\n",
    "train_idx = 0\n",
    "test_idx = 0\n",
    "for idx in range(num_views):\n",
    "    if idx % 8 != 0:\n",
    "        image_file = model_path + '/train/ours_7000/renders/' + str(train_idx).zfill(5) + '.png'\n",
    "        depth_file = model_path + '/train/ours_7000/renders/' + str(train_idx).zfill(5) + '_depth.png'\n",
    "        train_idx += 1\n",
    "    else:\n",
    "        image_file = model_path + '/test/ours_7000/renders/' + str(test_idx).zfill(5) + '.png'\n",
    "        depth_file = model_path + '/test/ours_7000/renders/' + str(test_idx).zfill(5) + '_depth.png'\n",
    "        test_idx += 1\n",
    "    image = plt.imread(image_file)\n",
    "    images.append(image*255)\n",
    "    depth_image = plt.imread(depth_file)\n",
    "    if depth_image.min() < global_min:\n",
    "        global_min = depth_image.min()\n",
    "    if depth_image.max() > global_max:\n",
    "        global_max = depth_image.max()\n",
    "    depth_images.append(depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12156863 1.0\n"
     ]
    }
   ],
   "source": [
    "# print global min and max\n",
    "print(global_min, global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all depths should be mapped from global_min global_max to 0 255\n",
    "for idx, depth_image in enumerate(depth_images):\n",
    "    depth_images[idx] = (depth_image - global_min) / (global_max - global_min) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = model_path + '/visualization/allcameras.mp4'\n",
    "depth_path = model_path + '/visualization/allcameras_depth.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras.mp4.\n",
      "Moviepy - Writing video /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras.mp4\n",
      "Video saved to /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras.mp4\n",
      "Moviepy - Building video /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras_depth.mp4.\n",
      "Moviepy - Writing video /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras_depth.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras_depth.mp4\n",
      "Video saved to /home/sierra/gaussian-splatting/eval/invivo57/visualization/allcameras_depth.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "clip = ImageSequenceClip(list(images), fps=15)\n",
    "clip.write_videofile(output_path, codec='libx264', audio=False)\n",
    "print(f'Video saved to {output_path}')\n",
    "\n",
    "clip = ImageSequenceClip(list(depth_images), fps=15)\n",
    "clip.write_videofile(depth_path, codec='libx264', audio=False)\n",
    "print(f'Video saved to {depth_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_array = render_mask_gaussians(model_path, percent_of_gaussians=1, camera_index=novel_view_camera_id)\n",
    "img = Image.fromarray(img_array, 'RGB')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images = []\n",
    "\n",
    "cam_path = os.path.join(model_path, 'cameras.json')\n",
    "camera_idx_map = load_camera_map(cam_path)\n",
    "\n",
    "for i in range(num_views):\n",
    "    camera_idx = camera_idx_map.get(i)\n",
    "    if camera_idx is not None:\n",
    "        img_array = render_mask_gaussians(model_path, percent_of_gaussians=i/num_views, camera_index=camera_idx)\n",
    "        images.append(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create video from all frames in full_path using moviepy\n",
    "clip = ImageSequenceClip(images, fps=15)\n",
    "clip.write_videofile(output_path, codec='libx264', audio=False)\n",
    "print(f'Video saved to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spiral = generate_spiral_cam_to_world(radii=[0.1, 0.1, 0.1], focus_depth=center_camera.FoVx, n_poses=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
